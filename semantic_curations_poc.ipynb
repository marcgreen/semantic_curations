{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiyGzZE2luF8rdNotVOlnJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio youtube_transcript_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33qj6CRajaV3",
        "outputId": "5a697cb5-ec79-49e1-b7fe-2039dbea8751"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.11.0-py3-none-any.whl (11.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6 MB 4.3 MB/s \n",
            "\u001b[?25hCollecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-0.5.0-py3-none-any.whl (23 kB)\n",
            "Collecting orjson\n",
            "  Downloading orjson-3.8.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
            "\u001b[K     |████████████████████████████████| 278 kB 23.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from gradio) (2.11.3)\n",
            "Collecting markdown-it-py[linkify,plugins]\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 842 kB/s \n",
            "\u001b[?25hCollecting fastapi\n",
            "  Downloading fastapi-0.87.0-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting h11<0.13,>=0.11\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 732 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.23.0)\n",
            "Collecting websockets>=10.0\n",
            "  Downloading websockets-10.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.21.6)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 25.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Collecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from gradio) (1.10.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Collecting httpx\n",
            "  Downloading httpx-0.23.1-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.20.0-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 657 kB/s \n",
            "\u001b[?25hCollecting paramiko\n",
            "  Downloading paramiko-2.12.0-py2.py3-none-any.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 39.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from gradio) (2022.11.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from gradio) (3.8.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.8.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.1.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (0.13.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (2.10)\n",
            "Collecting starlette==0.21.0\n",
            "  Downloading starlette-0.21.0-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 812 kB/s \n",
            "\u001b[?25hCollecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx->gradio) (2022.9.24)\n",
            "Collecting httpcore<0.17.0,>=0.15.0\n",
            "  Downloading httpcore-0.16.1-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 5.9 MB/s \n",
            "\u001b[?25h  Downloading httpcore-0.16.0-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 6.0 MB/s \n",
            "\u001b[?25h  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->gradio) (2.0.1)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting mdit-py-plugins\n",
            "  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting linkify-it-py~=1.0\n",
            "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
            "Collecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->gradio) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2022.6)\n",
            "Collecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[K     |████████████████████████████████| 856 kB 62.2 MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (593 kB)\n",
            "\u001b[K     |████████████████████████████████| 593 kB 37.4 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "  Downloading cryptography-38.0.3-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 39.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.5->paramiko->gradio) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio) (2.21)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (1.24.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (7.1.2)\n",
            "Building wheels for collected packages: ffmpy, python-multipart\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4711 sha256=92f17eb175eaefd3d02695d301f209860dd8c2c89fc3a3ba73894831b0cb89f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/e4/6c/e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=738960ec820d46bcc51bd0320fe2231b612738ac993dcf3c1aceb4bca575f445\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\n",
            "Successfully built ffmpy python-multipart\n",
            "Installing collected packages: sniffio, mdurl, uc-micro-py, rfc3986, markdown-it-py, h11, anyio, starlette, pynacl, mdit-py-plugins, linkify-it-py, httpcore, cryptography, bcrypt, websockets, uvicorn, python-multipart, pydub, pycryptodome, paramiko, orjson, httpx, ffmpy, fastapi, youtube-transcript-api, gradio\n",
            "Successfully installed anyio-3.6.2 bcrypt-4.0.1 cryptography-38.0.3 fastapi-0.87.0 ffmpy-0.3.0 gradio-3.11.0 h11-0.12.0 httpcore-0.15.0 httpx-0.23.1 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.1 mdurl-0.1.2 orjson-3.8.2 paramiko-2.12.0 pycryptodome-3.15.0 pydub-0.25.1 pynacl-1.5.0 python-multipart-0.0.5 rfc3986-1.5.0 sniffio-1.3.0 starlette-0.21.0 uc-micro-py-1.0.1 uvicorn-0.20.0 websockets-10.4 youtube-transcript-api-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2iziUbSYjJXE"
      },
      "outputs": [],
      "source": [
        "import gradio\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "\n",
        "def yt2transcript(video_id):\n",
        "  print(f\"\\n\\nid: {video_id}\")\n",
        "\n",
        "  # data looks like [{'text': 'hey friends welcome to one little coder', 'start': 0.84, 'duration': 4.38}, ...]\n",
        "  data = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "  transcript = ' '.join([x['text'] for x in data])\n",
        "\n",
        "  # TODO if there is no transcript (how likely is this?), run through whisper-large on hf (but 30k free characters per month)\n",
        "\n",
        "  return transcript\n",
        "\n",
        "#demo = gr.Interface(fn=yt2transcript, inputs=[\"text\"], outputs=[\"text\"])\n",
        "                    #article=\"\\n\".join([f\"- {k}: \" + v.replace(\"\\n\",\" \") for k,v in instructions.items()]))\n",
        "#demo.launch(debug=True, share=True)   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_id = \"mbn6yLcoyzo\"\n",
        "print(yt2transcript(video_id))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPX0Gswb2BBX",
        "outputId": "0b18624f-d497-4bae-a3aa-1dab7a14d392"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "id: mbn6yLcoyzo\n",
            "hey friends welcome to one little coder if you ever wanted to build a machine learning application you would know that sometimes you have to wrap this entire machine learning application as an API so for your application you need front-end and back-end sometimes your front end could be not python for example it could be react.js it could be angularjsr it could be any JavaScript framework that you want to use while the backend being powered by Python and most of the time people actually use apis for it the APA is communicating to the front end and making calls to the server and this is how the full stack application is going to look like but traditionally if you wanted to use an API you need to host it on a server and then use something like Fast API and then get the APA so this is what we have been doing all the while but today or probably yesterday night radio announced a new feature where you can use gradu as an API this has been there for a while we probably would have discussed this in this Channel as well but now this has been revamped and then you have got use radio as an APA as an option which means you can now create a machine learning application host it on hugging face spaces now use that as an APA rather than a full stack application on any web application that you are going to develop and to show this demo I'm going to build a streamlined application which is no way connected to radio which is no way connected to hugging phase but this stream unit application which is running on my local machine is going to be powered by that gradio API which we are going to see how to create in a short while let's get started with this radio API first I got to know about this announcement from abubakar's tweet and this is very simple so at the end of a radio Uplink if you are running a radio application that is greater than 3.11 you're going to see a very small button at the bottom called use via API and once you click that you're going to get all the details first let me show you what is happening here in this application this is a text to speech application which is powered by radio API which is hosted on hugging face spaces first I have to go here and then enter a text for example I can literally copy this from abubakar's tweet and paste it copy come back paste it and then click the text to speech magic which is a streamlit button and then when I run to share radio's new use my rappy cage okay we are not here to evaluate how the T text to to speech is working but we can see that this is completely working fine and this is right now working on my local machine and now what does it mean let me take you inside the code and show you what is happening to quickly see what is happening this is a very simple streamlit application but the way this text to speech is happening is by making an APA call to the APA that is hosted on hugging fee spaces now let us identify how that is happening anytime you have a hugging face page that is is actually running greater than 3.11 go click the file version click the readme and then see so this SDK version is 3.11 so if any grade your application that is hosted on hugging face spaces that is greater than 3.11 you're going to see a very small icon at the bottom so if I zoom in you're going to see a very small icon that says use via APA and once you click that it's going to take you to this very nice page like if you are familiar with swagger very swagger like interface where you can see okay this is an API documentation for this space and this is the end point and for this end point you have to make a post request and this is your sample input payload and this is your output response object and this API documentation kudos to the team does not end here but also gives you sample code for Python and JavaScript so for python you can copy this code and literally run it it's going to give you a result for JavaScript you can copy this and add it to your is angularjs or whatever JavaScript framework that you are using given that we know how to see an EPA documentation for a particular hugging phase spaces that is basically a radio application let's now take this and go to an API platform and then see how does it work for that I'm going to use something called Hopscotch this is like an open source alternative for Postman if you are familiar with Postman so what I've done here is I've copied the endpoint here I've come to Hopscotch and I've pasted the end point now whenever there is an endpoint we need to make sure that is it a get request or is it a post request so instead of get I've selected post and now we need to make a call we need to make a call to the APA endpoint using an input payload so that is basically your text which is ideally going to be converted into speech which is going to be shown or displayed or responded back to you as a base 64 string which is the base64 encoded string of the audio so I have gone here and then gone to the body and then set my data the payload is like I want the base64 for hello world so or I can I can probably paste the same thing whatever the message here is you can copy this come back here paste the entire message okay we have we have the call we have the codes so really Stoke to share greatest new API let's stick to this now I can send and when I send this thing this Hopscotch is going to help me send a call using this payload to this endpoint as a post request which is a HTTP request the good thing is we have got 200 response which is Success which means the request that we made to the end point is successful and we have got a response right now it doesn't make any sense it doesn't make any sense because this is a base 64 encoded audio so I'm going to copy this just for us to understand and go to Google or wherever you want to and then search for base64 to MP3 and I'm going to see base64 to audio I'm going to paste it here and I'm going to click decode base64 to audio and then I'm going to play the audio do we have the audio here okay I still don't see the audio here cannot decode okay I should use basics for decoder you could base 64. okay the problem is because I had added the codes that's a terrible mistake foreign cool so now we know that this entire API thing works fine which is what we verified using Hopscotch by making a call to the hugging face APA endpoint using the input payload that we just gave the text here which says really stoked to Shared graders new API and then we got a base64 encoded string and response which we used to service base64.guru to convert into audio files so that we verified this entire thing works so now what we are going to do is we are going to just simply go here copy the beautiful python code that The Graduate team has put together for us and we are going to merge it or we are just going to combine this to a streamlined application and that's the whole point of this video just to show that the back end and the printing can stay separately just like most full stack applications so if you are a JavaScript developer and if you want to develop machine learning powered applications this is exactly what you have do not exactly but this is one of the things that you can do so now I'm going to go to my code editor which in this case is vs code and I've created a new folder a project folder and I've got a file called app dot Pi which is a streamlit application first I have to import certain required libraries which in this case is streamlit for full full stack application development a request for making HTTP calls base64 just for encoding and decoding then we have got a very beautiful title that says text to speech powered by gradu API hosted on hugging face spaces if you want to add then we are going to use streamlits input component text input to collect the input from the user which is going to be stored in in underscore text the next thing is we have enabled we have created a button called text to speech magic so if you see your application you can see text to speech magic like in case if you want to optimize it like for example let's say I want to do something like this with an icon maybe this yeah so we have a button that has text to speech magic the text and we are going to say once you click the button if the button is clicked we had word we are not specifying click here but you know that's what it means then we are going to use a progress bar or a spinner in this case and we are going to just use a code that we just copied from the gradio documentation this code and we will say making a call and the input payload instead of the hard-coded text you want to use the input text that we got from the user so that once we get the response instead of being it being a response object we are converting into a Json and then we are storing it here if you want you can call it Json response Json as well and then I can use that here so now we need an audio player for that we are going to Simply use an HTML audio player and this is a simple HTML tag and to embed the audio base64 encoded content inside it we are using IF string here this is an if string python if string and everything else is a string and here you have got the python object which is response underscore Json inside that data and inside the first object which is the base 64 encoded string and we have to also specify what type of audio content it is in this case it is audio slash Flack that's a type and once you you have the markdown or HTML you can just display the HTML using hd.markdon do not use this in production because this is prone to cross-site scripting and all these kind of things so this is just for demo to show that you can have front-end and backend separately all together so that's why it says unsafe allow HTML and we are enabling it true now save it once you save it go to your terminal click new terminal and once you get the new terminal you say streamlit run app.5 once you do that it is going to run this entire file to quickly summarize again we have loaded required libraries we have got a title we have got a widget that collects input from the user we have got a button and once the button is clicked we have we have a spinner that runs until we do all these things in this case make a post request to the hugging face spaces for the particular gradio API and use that to embed an audio player and you know display to the user so let me run this once I run this it's going to give me the link where it is run I can come back here once I run this you can see that the new button with with the lightning icon that we added is here and I can add something radio is amazing I just love it but streamlit is also equally amazing that's why this demo uses extremely takes click Text to Speech Magic we have got the audio output played radio is amazing I just love it but travel it is also equally amazing that's why this demo uses tremolite that's why this demo uses shrimlet and now we have successfully managed to build a full stack machine learning application that does speech to text the streamlit application is streamlit is the stack that is powering the full stack application but the front end is streamlit but the back end which is you know in this case streamlit but makes call HTTP calls using an APA to a radio application and that grade your application is hosted on hugging face spaces and that's the power of Open Source now what you can do is you can host your model on hugging face build a radio application on top of it host it on hugging face pieces and then use that API to build uh any kind of application whether it is a curl command whether it is a HTTP request or if you are building an R shiny application now you can use it anywhere in any programming language because it's just an EPA call which is quite possible in any programming language so you're not bound only by Python and whatever you want to do and that is why we used streamly to show that power say where we have a streamlined application that makes APA calls to the radio APA I hope this video was helpful to you once again kudos to the team for making this amazing new or enhanced APA option using radio but if you have any other question let me know in the comment section otherwise see you in the next video peace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ingest_transcript(transcript):\n",
        "  # TODO langchain and...elastic maybe? cognosis ai? qdrant/weaviate/pinecone?"
      ],
      "metadata": {
        "id": "y55crgN_3Sp2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
