{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkbD4KOWjAVoRkEAJNbXK2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "PINECONE_APIKEY = \"\"\n",
        "SUPABASE_URL = \"\"\n",
        "SUPABASE_KEY = \"\"\n",
        "\n",
        "!pip install gradio youtube_transcript_api langchain nltk sentence_transformers pinecone-client supabase"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33qj6CRajaV3",
        "outputId": "27782a4c-43a4-4a7f-ef29-4efbee112740"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.7/dist-packages (3.11.0)\n",
            "Requirement already satisfied: youtube_transcript_api in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.7/dist-packages (0.0.22)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.7/dist-packages (2.0.13)\n",
            "Requirement already satisfied: supabase in /usr/local/lib/python3.7/dist-packages (0.7.1)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.7/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.28.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.7/dist-packages (from gradio) (0.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from gradio) (3.8.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.7/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.7/dist-packages (from gradio) (0.0.5)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.7/dist-packages (from gradio) (0.23.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.3.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.7/dist-packages (from gradio) (3.16.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from gradio) (2022.11.0)\n",
            "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.7/dist-packages (from gradio) (10.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.21.6)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.7/dist-packages (from gradio) (0.87.0)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.7/dist-packages (from gradio) (3.8.2)\n",
            "Requirement already satisfied: paramiko in /usr/local/lib/python3.7/dist-packages (from gradio) (2.12.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from gradio) (1.10.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify,plugins] in /usr/local/lib/python3.7/dist-packages (from gradio) (2.1.0)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from langchain) (1.4.44)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.24.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.13.1+cu113)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.7.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.11.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.97)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.13.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from pinecone-client) (1.24.3)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pinecone-client) (2.2.1)\n",
            "Requirement already satisfied: loguru>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from pinecone-client) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (2.1.1)\n",
            "Requirement already satisfied: python-semantic-release==7.32.1 in /usr/local/lib/python3.7/dist-packages (from supabase) (7.32.1)\n",
            "Requirement already satisfied: realtime<0.0.6,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from supabase) (0.0.5)\n",
            "Requirement already satisfied: gotrue<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from supabase) (0.5.4)\n",
            "Requirement already satisfied: postgrest-py<0.11.0,>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from supabase) (0.10.3)\n",
            "Requirement already satisfied: storage3<0.4.0,>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from supabase) (0.3.5)\n",
            "Requirement already satisfied: supafunc<0.3.0,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from supabase) (0.2.2)\n",
            "Requirement already satisfied: semver<3,>=2.10 in /usr/local/lib/python3.7/dist-packages (from python-semantic-release==7.32.1->supabase) (2.13.0)\n",
            "Requirement already satisfied: python-gitlab<4,>=2 in /usr/local/lib/python3.7/dist-packages (from python-semantic-release==7.32.1->supabase) (3.11.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from python-semantic-release==7.32.1->supabase) (0.38.4)\n",
            "Requirement already satisfied: tomlkit~=0.10 in /usr/local/lib/python3.7/dist-packages (from python-semantic-release==7.32.1->supabase) (0.11.6)\n",
            "Requirement already satisfied: dotty-dict<2,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from python-semantic-release==7.32.1->supabase) (1.3.1)\n",
            "Requirement already satisfied: click-log<1,>=0.3 in /usr/local/lib/python3.7/dist-packages (from python-semantic-release==7.32.1->supabase) (0.4.0)\n",
            "Requirement already satisfied: twine<4,>=3 in /usr/local/lib/python3.7/dist-packages (from python-semantic-release==7.32.1->supabase) (3.7.1)\n",
            "Requirement already satisfied: gitpython<4,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from python-semantic-release==7.32.1->supabase) (3.1.29)\n",
            "Requirement already satisfied: invoke<2,>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from python-semantic-release==7.32.1->supabase) (1.7.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython<4,>=3.0.8->python-semantic-release==7.32.1->supabase) (4.0.10)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.0.8->python-semantic-release==7.32.1->supabase) (5.0.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx->gradio) (1.5.0)\n",
            "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from httpx->gradio) (0.15.0)\n",
            "Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.7/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
            "Requirement already satisfied: deprecation<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from postgrest-py<0.11.0,>=0.10.2->supabase) (2.1.0)\n",
            "Requirement already satisfied: requests-toolbelt>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from python-gitlab<4,>=2->python-semantic-release==7.32.1->supabase) (0.10.1)\n",
            "Requirement already satisfied: dataclasses<0.7,>=0.6 in /usr/local/lib/python3.7/dist-packages (from realtime<0.0.6,>=0.0.5->supabase) (0.6)\n",
            "Requirement already satisfied: readme-renderer>=21.0 in /usr/local/lib/python3.7/dist-packages (from twine<4,>=3->python-semantic-release==7.32.1->supabase) (37.3)\n",
            "Requirement already satisfied: colorama>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from twine<4,>=3->python-semantic-release==7.32.1->supabase) (0.4.6)\n",
            "Requirement already satisfied: keyring>=15.1 in /usr/local/lib/python3.7/dist-packages (from twine<4,>=3->python-semantic-release==7.32.1->supabase) (23.11.0)\n",
            "Requirement already satisfied: pkginfo>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from twine<4,>=3->python-semantic-release==7.32.1->supabase) (1.8.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence_transformers) (3.10.0)\n",
            "Requirement already satisfied: SecretStorage>=3.2 in /usr/local/lib/python3.7/dist-packages (from keyring>=15.1->twine<4,>=3->python-semantic-release==7.32.1->supabase) (3.3.3)\n",
            "Requirement already satisfied: jeepney>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from keyring>=15.1->twine<4,>=3->python-semantic-release==7.32.1->supabase) (0.8.0)\n",
            "Requirement already satisfied: jaraco.classes in /usr/local/lib/python3.7/dist-packages (from keyring>=15.1->twine<4,>=3->python-semantic-release==7.32.1->supabase) (3.2.3)\n",
            "Requirement already satisfied: Pygments>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from readme-renderer>=21.0->twine<4,>=3->python-semantic-release==7.32.1->supabase) (2.6.1)\n",
            "Requirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from readme-renderer>=21.0->twine<4,>=3->python-semantic-release==7.32.1->supabase) (0.17.1)\n",
            "Requirement already satisfied: bleach>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from readme-renderer>=21.0->twine<4,>=3->python-semantic-release==7.32.1->supabase) (5.0.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach>=2.1.0->readme-renderer>=21.0->twine<4,>=3->python-semantic-release==7.32.1->supabase) (0.5.1)\n",
            "Requirement already satisfied: cryptography>=2.0 in /usr/local/lib/python3.7/dist-packages (from SecretStorage>=3.2->keyring>=15.1->twine<4,>=3->python-semantic-release==7.32.1->supabase) (38.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine<4,>=3->python-semantic-release==7.32.1->supabase) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine<4,>=3->python-semantic-release==7.32.1->supabase) (2.21)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (6.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.8.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (0.13.0)\n",
            "Requirement already satisfied: starlette==0.21.0 in /usr/local/lib/python3.7/dist-packages (from fastapi->gradio) (0.21.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from jaraco.classes->keyring>=15.1->twine<4,>=3->python-semantic-release==7.32.1->supabase) (9.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->gradio) (2.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.7/dist-packages (from markdown-it-py[linkify,plugins]->gradio) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py~=1.0 in /usr/local/lib/python3.7/dist-packages (from markdown-it-py[linkify,plugins]->gradio) (1.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.7/dist-packages (from markdown-it-py[linkify,plugins]->gradio) (0.3.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.7/dist-packages (from linkify-it-py~=1.0->markdown-it-py[linkify,plugins]->gradio) (1.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2022.6)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (4.0.1)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->langchain) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2iziUbSYjJXE"
      },
      "outputs": [],
      "source": [
        "import gradio\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "def yt2transcript(video_id):\n",
        "  print(f\"\\n\\nid: {video_id}\")\n",
        "\n",
        "  # data looks like [{'text': 'hey friends welcome to one little coder', 'start': 0.84, 'duration': 4.38}, ...]\n",
        "  data = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "  transcript = ' '.join([x['text'] for x in data])\n",
        "\n",
        "  # TODO if there is no transcript (how likely is this?), run through whisper-large on hf (but 30k free characters per month)\n",
        "\n",
        "  return transcript\n",
        "\n",
        "#demo = gr.Interface(fn=yt2transcript, inputs=[\"text\"], outputs=[\"text\"])\n",
        "                    #article=\"\\n\".join([f\"- {k}: \" + v.replace(\"\\n\",\" \") for k,v in instructions.items()]))\n",
        "#demo.launch(debug=True, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_id = \"mbn6yLcoyzo\"\n",
        "transcript = yt2transcript(video_id)\n",
        "print(transcript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPX0Gswb2BBX",
        "outputId": "230eff0b-2df5-4966-a00c-893fdc6c7d1a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "id: mbn6yLcoyzo\n",
            "hey friends welcome to one little coder if you ever wanted to build a machine learning application you would know that sometimes you have to wrap this entire machine learning application as an API so for your application you need front-end and back-end sometimes your front end could be not python for example it could be react.js it could be angularjsr it could be any JavaScript framework that you want to use while the backend being powered by Python and most of the time people actually use apis for it the APA is communicating to the front end and making calls to the server and this is how the full stack application is going to look like but traditionally if you wanted to use an API you need to host it on a server and then use something like Fast API and then get the APA so this is what we have been doing all the while but today or probably yesterday night radio announced a new feature where you can use gradu as an API this has been there for a while we probably would have discussed this in this Channel as well but now this has been revamped and then you have got use radio as an APA as an option which means you can now create a machine learning application host it on hugging face spaces now use that as an APA rather than a full stack application on any web application that you are going to develop and to show this demo I'm going to build a streamlined application which is no way connected to radio which is no way connected to hugging phase but this stream unit application which is running on my local machine is going to be powered by that gradio API which we are going to see how to create in a short while let's get started with this radio API first I got to know about this announcement from abubakar's tweet and this is very simple so at the end of a radio Uplink if you are running a radio application that is greater than 3.11 you're going to see a very small button at the bottom called use via API and once you click that you're going to get all the details first let me show you what is happening here in this application this is a text to speech application which is powered by radio API which is hosted on hugging face spaces first I have to go here and then enter a text for example I can literally copy this from abubakar's tweet and paste it copy come back paste it and then click the text to speech magic which is a streamlit button and then when I run to share radio's new use my rappy cage okay we are not here to evaluate how the T text to to speech is working but we can see that this is completely working fine and this is right now working on my local machine and now what does it mean let me take you inside the code and show you what is happening to quickly see what is happening this is a very simple streamlit application but the way this text to speech is happening is by making an APA call to the APA that is hosted on hugging fee spaces now let us identify how that is happening anytime you have a hugging face page that is is actually running greater than 3.11 go click the file version click the readme and then see so this SDK version is 3.11 so if any grade your application that is hosted on hugging face spaces that is greater than 3.11 you're going to see a very small icon at the bottom so if I zoom in you're going to see a very small icon that says use via APA and once you click that it's going to take you to this very nice page like if you are familiar with swagger very swagger like interface where you can see okay this is an API documentation for this space and this is the end point and for this end point you have to make a post request and this is your sample input payload and this is your output response object and this API documentation kudos to the team does not end here but also gives you sample code for Python and JavaScript so for python you can copy this code and literally run it it's going to give you a result for JavaScript you can copy this and add it to your is angularjs or whatever JavaScript framework that you are using given that we know how to see an EPA documentation for a particular hugging phase spaces that is basically a radio application let's now take this and go to an API platform and then see how does it work for that I'm going to use something called Hopscotch this is like an open source alternative for Postman if you are familiar with Postman so what I've done here is I've copied the endpoint here I've come to Hopscotch and I've pasted the end point now whenever there is an endpoint we need to make sure that is it a get request or is it a post request so instead of get I've selected post and now we need to make a call we need to make a call to the APA endpoint using an input payload so that is basically your text which is ideally going to be converted into speech which is going to be shown or displayed or responded back to you as a base 64 string which is the base64 encoded string of the audio so I have gone here and then gone to the body and then set my data the payload is like I want the base64 for hello world so or I can I can probably paste the same thing whatever the message here is you can copy this come back here paste the entire message okay we have we have the call we have the codes so really Stoke to share greatest new API let's stick to this now I can send and when I send this thing this Hopscotch is going to help me send a call using this payload to this endpoint as a post request which is a HTTP request the good thing is we have got 200 response which is Success which means the request that we made to the end point is successful and we have got a response right now it doesn't make any sense it doesn't make any sense because this is a base 64 encoded audio so I'm going to copy this just for us to understand and go to Google or wherever you want to and then search for base64 to MP3 and I'm going to see base64 to audio I'm going to paste it here and I'm going to click decode base64 to audio and then I'm going to play the audio do we have the audio here okay I still don't see the audio here cannot decode okay I should use basics for decoder you could base 64. okay the problem is because I had added the codes that's a terrible mistake foreign cool so now we know that this entire API thing works fine which is what we verified using Hopscotch by making a call to the hugging face APA endpoint using the input payload that we just gave the text here which says really stoked to Shared graders new API and then we got a base64 encoded string and response which we used to service base64.guru to convert into audio files so that we verified this entire thing works so now what we are going to do is we are going to just simply go here copy the beautiful python code that The Graduate team has put together for us and we are going to merge it or we are just going to combine this to a streamlined application and that's the whole point of this video just to show that the back end and the printing can stay separately just like most full stack applications so if you are a JavaScript developer and if you want to develop machine learning powered applications this is exactly what you have do not exactly but this is one of the things that you can do so now I'm going to go to my code editor which in this case is vs code and I've created a new folder a project folder and I've got a file called app dot Pi which is a streamlit application first I have to import certain required libraries which in this case is streamlit for full full stack application development a request for making HTTP calls base64 just for encoding and decoding then we have got a very beautiful title that says text to speech powered by gradu API hosted on hugging face spaces if you want to add then we are going to use streamlits input component text input to collect the input from the user which is going to be stored in in underscore text the next thing is we have enabled we have created a button called text to speech magic so if you see your application you can see text to speech magic like in case if you want to optimize it like for example let's say I want to do something like this with an icon maybe this yeah so we have a button that has text to speech magic the text and we are going to say once you click the button if the button is clicked we had word we are not specifying click here but you know that's what it means then we are going to use a progress bar or a spinner in this case and we are going to just use a code that we just copied from the gradio documentation this code and we will say making a call and the input payload instead of the hard-coded text you want to use the input text that we got from the user so that once we get the response instead of being it being a response object we are converting into a Json and then we are storing it here if you want you can call it Json response Json as well and then I can use that here so now we need an audio player for that we are going to Simply use an HTML audio player and this is a simple HTML tag and to embed the audio base64 encoded content inside it we are using IF string here this is an if string python if string and everything else is a string and here you have got the python object which is response underscore Json inside that data and inside the first object which is the base 64 encoded string and we have to also specify what type of audio content it is in this case it is audio slash Flack that's a type and once you you have the markdown or HTML you can just display the HTML using hd.markdon do not use this in production because this is prone to cross-site scripting and all these kind of things so this is just for demo to show that you can have front-end and backend separately all together so that's why it says unsafe allow HTML and we are enabling it true now save it once you save it go to your terminal click new terminal and once you get the new terminal you say streamlit run app.5 once you do that it is going to run this entire file to quickly summarize again we have loaded required libraries we have got a title we have got a widget that collects input from the user we have got a button and once the button is clicked we have we have a spinner that runs until we do all these things in this case make a post request to the hugging face spaces for the particular gradio API and use that to embed an audio player and you know display to the user so let me run this once I run this it's going to give me the link where it is run I can come back here once I run this you can see that the new button with with the lightning icon that we added is here and I can add something radio is amazing I just love it but streamlit is also equally amazing that's why this demo uses extremely takes click Text to Speech Magic we have got the audio output played radio is amazing I just love it but travel it is also equally amazing that's why this demo uses tremolite that's why this demo uses shrimlet and now we have successfully managed to build a full stack machine learning application that does speech to text the streamlit application is streamlit is the stack that is powering the full stack application but the front end is streamlit but the back end which is you know in this case streamlit but makes call HTTP calls using an APA to a radio application and that grade your application is hosted on hugging face spaces and that's the power of Open Source now what you can do is you can host your model on hugging face build a radio application on top of it host it on hugging face pieces and then use that API to build uh any kind of application whether it is a curl command whether it is a HTTP request or if you are building an R shiny application now you can use it anywhere in any programming language because it's just an EPA call which is quite possible in any programming language so you're not bound only by Python and whatever you want to do and that is why we used streamly to show that power say where we have a streamlined application that makes APA calls to the radio APA I hope this video was helpful to you once again kudos to the team for making this amazing new or enhanced APA option using radio but if you have any other question let me know in the comment section otherwise see you in the next video peace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Interface for Pinecone vector stores.\"\"\"\n",
        "import uuid\n",
        "import pinecone\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Any, Callable, Dict, Iterable, List, Optional\n",
        "\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.embeddings.base import Embeddings\n",
        "from langchain.vectorstores.base import VectorStore\n",
        "\n",
        "\n",
        "class Pinecone(VectorStore):\n",
        "    \"\"\"Interface for vector stores.\"\"\"\n",
        "\n",
        "    def _query():\n",
        "      pass\n",
        "\n",
        "    def __init__(\n",
        "        self, api_key: str, index_name: str, embedding_function: Callable\n",
        "    ):\n",
        "        \"\"\"Initialize with necessary components.\"\"\"\n",
        "        try:\n",
        "            import pinecone\n",
        "        except ImportError:\n",
        "            raise ValueError(\n",
        "                \"Could not import pinecone python package. \"\n",
        "                \"Please install it with `pip install pinecone-client`.\"\n",
        "            )\n",
        "        self.embedding_function = embedding_function\n",
        "        self.index_name = index_name\n",
        "        #try:\n",
        "        pinecone.init(\n",
        "           api_key=api_key,\n",
        "           environment='us-west1-gcp' # only option for for free tier\n",
        "        )\n",
        "        #except ValueError as e:\n",
        "        #    raise ValueError(\n",
        "        #        f\"Your elasticsearch client string is misformatted. Got error: {e} \"\n",
        "         #   )\n",
        "        self.client = pinecone\n",
        "\n",
        "    def add_texts(\n",
        "        self, texts: Iterable[str], metadatas: Optional[List[dict]] = None\n",
        "    ) -> None:\n",
        "        \"\"\"Run more texts through the embeddings and add to the vectorstore.\"\"\"\n",
        "        index = self.client.Index(self.index_name)\n",
        "        batch_size = 16 # recommended limit is 100 vectors\n",
        "        for i in range(0, len(texts), batch_size):\n",
        "          i_end = min(i+batch_size, len(texts))\n",
        "          text_batch = texts[i:i_end]\n",
        "          metadata_batch = metadatas[i:i_end] if metadatas else [{}] * (i_end-i)\n",
        "          embedding_batch = self.embedding_function(text_batch) # [[0] * 768] * (i_end - i) #\n",
        "          to_upsert = [\n",
        "              (\n",
        "                  str(uuid.uuid4()), # id that we currently don't care about\n",
        "                  embedding.tolist(),\n",
        "                  dict(\n",
        "                      {\"text\": text},\n",
        "                      **metadata # if 'text' in here too, it takes precendence\n",
        "                  )\n",
        "              ) for text, embedding, metadata in zip(text_batch, embedding_batch, metadata_batch)\n",
        "          ]\n",
        "          print(embedding_batch)\n",
        "          print(999999)\n",
        "          print(i, len(texts)/batch_size, to_upsert)\n",
        "          index.upsert(vectors=to_upsert)\n",
        "\n",
        "    def similarity_search(self, query: str, k: int = 4) -> List[Document]:\n",
        "        \"\"\"Return docs most similar to query.\"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def from_texts(\n",
        "        cls,\n",
        "        texts: List[str],\n",
        "        embedding: Embeddings,\n",
        "        metadatas: Optional[List[dict]] = None,\n",
        "        **kwargs: Any\n",
        "    ) -> \"VectorStore\":\n",
        "        \"\"\"Return VectorStore initialized from texts and embeddings.\"\"\"\n",
        "\n",
        "# TODO fill out other 2 methods for Pinecone Vectore Store and ask if harrison would be open to a PR\n",
        "# TODO account for mpnet's limit of 384 word pieces per chunk (is it done already?)\n",
        "# DONE need to check if embeddings exist for given video id before generating embeddings\n",
        "# supabase to store index (apparently can't rely on vector db to do it?) and user's curations / popular curations\n",
        "# - paused after 1 week inactivity (and i believe pinecone index DELETED after some days of inactivity?!)\n",
        "# - - TODO backup both pinecone and supabase daily (this should count as the activity), and make publicly accessible\n",
        "# TODO user prefs data model (their curations), and curation data model\n"
      ],
      "metadata": {
        "id": "y55crgN_3Sp2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import SpacyTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embedder = HuggingFaceEmbeddings().embed_documents\n",
        "model_name = HuggingFaceEmbeddings().model_name \n",
        "\n",
        "from supabase import create_client, Client\n",
        "\n",
        "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "\n",
        "def transcript2chunks(transcript):\n",
        "  return SpacyTextSplitter().split_text(transcript)\n",
        "\n",
        "def ingest_transcript(transcript):\n",
        "  p = Pinecone(PINECONE_APIKEY, 'semantic-curations', embedder)\n",
        "  chunks = transcript2chunks(transcript) \n",
        "  p.add_texts(chunks, [{'yt_video_id': video_id}] * len(chunks))\n",
        "\n",
        "def already_ingested(yt_video_id: str):\n",
        "  data = supabase.table(\"ingested_youtube_videos\").select(\"*\", count=\"estimated\").eq('video_id', yt_video_id).execute()\n",
        "  return data.count > 0\n",
        "\n",
        "def ingest_video(video_id):\n",
        "  if already_ingested(video_id):\n",
        "    return \"dupe\"\n",
        "  else:\n",
        "    p = Pinecone(PINECONE_APIKEY, 'semantic-curations', embedder)\n",
        "    transcript = yt2transcript(video_id)\n",
        "    chunks = transcript2chunks(transcript)\n",
        "    p.add_texts(chunks, [{'yt_video_id': video_id}] * len(chunks))\n",
        "    data = supabase.table(\"ingested_youtube_videos\").insert({\"video_id\": video_id, \"embedding_model\": model_name}).execute()\n",
        "    return \"ingested\"\n",
        "\n",
        "ingest_video(video_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mIaZbaTpetGL",
        "outputId": "ab95d368-7107-4236-9c16-6d097a427324"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dupe'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chunks = transcript2chunks(transcript)\n",
        "print(len(chunks), [len(x) for x in chunks])"
      ],
      "metadata": {
        "id": "7xAnxGZO6gon"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}